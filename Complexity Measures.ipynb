{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as t\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from scipy.sparse.csgraph import minimum_spanning_tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data = load_iris()\n",
    "#data = load_breast_cancer()\n",
    "y = data.target\n",
    "X = data.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Some useful things to support complexity measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_fx(X: np.ndarray, y: np.ndarray) -> t.Dict[str, t.Any]:\n",
    "    \"\"\"Precompute some useful things to support complexity measures.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : :obj:`np.ndarray`, optional\n",
    "            Attributes from fitted data.\n",
    "    y : :obj:`np.ndarray`, optional\n",
    "            Target attribute from fitted data.\n",
    "    Returns\n",
    "    -------\n",
    "    :obj:`dict`\n",
    "        With following precomputed items:\n",
    "        - ``ovo_comb`` (:obj:`list`): List of all class OVO combination, \n",
    "            i.e., [(0,1), (0,2) ...].\n",
    "        - ``cls_index`` (:obj:`list`):  The list of boolean vectors\n",
    "            indicating the example of each class. \n",
    "        - ``cls_n_ex`` (:obj:`np.ndarray`): The number of examples in\n",
    "            each class. The array indexes represent the classes.\n",
    "    \"\"\"\n",
    "\n",
    "    prepcomp_vals = {}\n",
    "    \n",
    "    classes, class_freqs = np.unique(y, return_counts=True)\n",
    "    cls_index = [np.equal(y, i) for i in range(classes.shape[0])]\n",
    "\n",
    "    #cls_n_ex = np.array([np.sum(aux) for aux in cls_index])\n",
    "    cls_n_ex = list(class_freqs)\n",
    "    ovo_comb = list(itertools.combinations(range(classes.shape[0]), 2))\n",
    "    prepcomp_vals[\"ovo_comb\"] = ovo_comb\n",
    "    prepcomp_vals[\"cls_index\"] = cls_index\n",
    "    prepcomp_vals[\"cls_n_ex\"] = cls_n_ex\n",
    "    return prepcomp_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "precomp_fx = precompute_fx(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_index = precomp_fx['cls_index']\n",
    "cls_n_ex = precomp_fx['cls_n_ex']\n",
    "ovo_comb = precomp_fx['ovo_comb']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature-based Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum Fisher’s Discriminant Ratio (F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerator (X: np.ndarray, cls_index, cls_n_ex, i) -> float:\n",
    "    return np.sum([cls_n_ex[j]*np.power((np.mean(X[cls_index[j], i])-\n",
    "                                         np.mean(X[:, i], axis=0)),2) for j in range (len(cls_index))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denominator (X: np.ndarray, cls_index, cls_n_ex, i) -> float:\n",
    "    return np.sum([np.sum(np.power(X[cls_index[j], i]-np.mean(X[cls_index[j], i], axis=0), 2)) \n",
    "                   for j in range(0, len(cls_n_ex))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rfi (X: np.ndarray, cls_index, cls_n_ex) -> float:\n",
    "    return [numerator (X, cls_index, cls_n_ex, i)/denominator(X, cls_index, cls_n_ex, i)\n",
    "            for i in range(np.shape(X)[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_F1(X: np.ndarray, cls_index: np.ndarray, cls_n_ex: np.ndarray) -> float:\n",
    "    return 1/(1 + np.max(compute_rfi (X, cls_index, cls_n_ex)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05862828094263205"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_F1(X, cls_index, cls_n_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Directional-vector Maximum Fisher’s Discriminant Ratio (F1v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_F1v(X: np.ndarray, ovo_comb: np.ndarray, cls_index: np.ndarray) ->float:\n",
    "    df_list = []\n",
    "    \n",
    "    for idx1, idx2 in ovo_comb:\n",
    "        y_class1 = cls_index[idx1]\n",
    "        y_class2 = cls_index[idx2]\n",
    "        dF = dVector(X, y_class1, y_class2)\n",
    "        df_list.append(1/(1+dF))\n",
    "        \n",
    "    return np.mean(df_list)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dVector(X: np.ndarray, y_class1: np.ndarray, y_class2: np.ndarray) -> float:\n",
    "    X_class1 = X[y_class1]; u_class1 = np.mean(X_class1, axis= 0)\n",
    "    X_class2 = X[y_class2]; u_class2 = np.mean(X_class2, axis= 0)\n",
    "    \n",
    "    W = ((np.shape(X_class1)[0]/ (np.shape(X_class1)[0] + np.shape(X_class2)[0]))* np.cov(X_class1.T)) \\\n",
    "     + (np.shape(X_class2)[0]/(np.shape(X_class1)[0] + (np.shape(X_class2)[0])) * np.cov(X_class2.T))\n",
    "    \n",
    "    d = np.dot(np.linalg.inv(W), (u_class1 - u_class2))\n",
    "    \n",
    "    B = np.dot((u_class1 - u_class2),((u_class1 - u_class2).T))\n",
    "    \n",
    "    return np.dot(np.dot(d.T, B), d)/ np.dot(np.dot(d.T, W), d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010007003139831777"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_F1v(X, ovo_comb, cls_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Volume of Overlapping Region (F2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _minmax(X: np.ndarray, class1: np.ndarray, class2: np.ndarray) -> np.ndarray:\n",
    "    \"\"\" This function computes the minimum of the maximum values per class\n",
    "    for all features.\n",
    "    \"\"\"\n",
    "    max_cls = np.zeros((2, X.shape[1]))\n",
    "    max_cls[0, :] = np.max(X[class1], axis=0)\n",
    "    max_cls[1, :] = np.max(X[class2], axis=0)\n",
    "    aux = np.min(max_cls, axis=0)\n",
    "    \n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _minmin(X: np.ndarray, class1: np.ndarray, class2: np.ndarray) -> np.ndarray:\n",
    "    \"\"\" This function computes the minimum of the minimum values per class\n",
    "    for all features.\n",
    "    \"\"\"\n",
    "    min_cls = np.zeros((2, X.shape[1]))\n",
    "    min_cls[0, :] = np.min(X[class1], axis=0)\n",
    "    min_cls[1, :] = np.min(X[class2], axis=0)\n",
    "    aux = np.min(min_cls, axis=0)\n",
    "    \n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _maxmin(X: np.ndarray, class1: np.ndarray, class2: np.ndarray) -> np.ndarray:\n",
    "    \"\"\" This function computes the maximum of the minimum values per class\n",
    "    for all features.\n",
    "    \"\"\"\n",
    "    min_cls = np.zeros((2, X.shape[1]))\n",
    "    min_cls[0, :] = np.min(X[class1], axis=0)\n",
    "    min_cls[1, :] = np.min(X[class2], axis=0)\n",
    "    aux = np.max(min_cls, axis=0)\n",
    "    \n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _maxmax(X: np.ndarray, class1: np.ndarray, class2: np.ndarray) -> np.ndarray:\n",
    "    \"\"\" This function computes the maximum of the maximum values per class\n",
    "    for all features. \n",
    "    \"\"\"\n",
    "    max_cls = np.zeros((2, X.shape[1]))\n",
    "    max_cls[0, :] = np.max(X[class1], axis=0)\n",
    "    max_cls[1, :] = np.max(X[class2], axis=0)\n",
    "    aux = np.max(max_cls, axis=0)\n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_F2(X: np.ndarray, ovo_comb: np.ndarray, cls_index: np.ndarray) -> float:\n",
    "    f2_list = []\n",
    "    \n",
    "    for idx1, idx2 in ovo_comb:\n",
    "        y_class1 = cls_index[idx1]\n",
    "        y_class2 = cls_index[idx2]\n",
    "        zero_ = np.zeros(np.shape(X)[1])\n",
    "        overlap_ = np.maximum(zero_, _minmax(X, y_class1, y_class2)-_maxmin(X, y_class1, y_class2))\n",
    "        range_ = _maxmax(X, y_class1, y_class2)-_minmin(X, y_class1, y_class2)\n",
    "        ratio = overlap_/range_\n",
    "        f2_list.append(np.prod(ratio))\n",
    "        \n",
    "    return np.mean(f2_list)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0063817663817663794"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_F2(X, ovo_comb, cls_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum Individual Feature Efficiency (F3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_f3(X_: np.ndarray, minmax_: np.ndarray, maxmin_: np.ndarray) -> np.ndarray:\n",
    "    \"\"\" This function computes the F3 complexity measure given minmax and maxmin.\"\"\"\n",
    "\n",
    "    overlapped_region_by_feature = np.logical_and(X_ >= maxmin_, X_ <= minmax_)\n",
    "\n",
    "    n_fi = np.sum(overlapped_region_by_feature, axis=0)\n",
    "    idx_min = np.argmin(n_fi)\n",
    "\n",
    "    return idx_min, n_fi, overlapped_region_by_feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_F3(X: np.ndarray, ovo_comb: np.ndarray, cls_index: np.ndarray, cls_n_ex: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"TODO\n",
    "    \"\"\"\n",
    "    f3 = []\n",
    "    for idx1, idx2 in ovo_comb:\n",
    "        idx_min, n_fi, _ = _compute_f3(X, _minmax(X, cls_index[idx1], cls_index[idx2]),\n",
    "        _maxmin(X, cls_index[idx1], cls_index[idx2]))\n",
    "    f3.append(n_fi[idx_min] / (cls_n_ex[idx1] + cls_n_ex[idx2]))\n",
    "\n",
    "    return np.mean(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_F3(X, ovo_comb, cls_index, cls_n_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collective Feature Efficiency (F4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_F4(X: np.ndarray, ovo_comb, cls_index, cls_n_ex) -> np.ndarray:\n",
    "    \"\"\"TODO\n",
    "    \"\"\"\n",
    "\n",
    "    f4 = []\n",
    "    for idx1, idx2 in ovo_comb:\n",
    "        aux = 0\n",
    "\n",
    "        y_class1 = cls_index[idx1]\n",
    "        y_class2 = cls_index[idx2]\n",
    "        sub_set = np.logical_or(y_class1, y_class2)\n",
    "        y_class1 = y_class1[sub_set]\n",
    "        y_class2 = y_class2[sub_set]\n",
    "        X_ = X[sub_set, :]\n",
    "        # X_ = X[np.logical_or(y_class1, y_class2),:]\n",
    "    \n",
    "        while X_.shape[1] > 0 and X_.shape[0] > 0:\n",
    "            # True if the example is in the overlapping region\n",
    "            idx_min, _, overlapped_region_by_feature = _compute_f3(X_,_minmax(X_, y_class1, y_class2),_maxmin(X_, y_class1, y_class2))\n",
    "\n",
    "            # boolean that if True, this example is in the overlapping region\n",
    "            overlapped_region = overlapped_region_by_feature[:, idx_min]\n",
    "\n",
    "            # removing the non overlapped features\n",
    "            X_ = X_[overlapped_region, :]\n",
    "            y_class1 = y_class1[overlapped_region]\n",
    "            y_class2 = y_class2[overlapped_region]\n",
    "\n",
    "            if X_.shape[0] > 0:\n",
    "                aux = X_.shape[0]\n",
    "            else:\n",
    "                aux = 0\n",
    "            \n",
    "            # removing the most efficient feature\n",
    "            X_ = np.delete(X_, idx_min, axis=1)\n",
    "\n",
    "        f4.append(aux/(cls_n_ex[idx1] + cls_n_ex[idx2]))\n",
    "    return np.mean(f4)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.043333333333333335"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_F4(X, ovo_comb, cls_index, cls_n_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neighborhood Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ratio of Intra/Extra Class Nearest Neighbor Distance (N2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_enemy (X: np.ndarray, y: np.ndarray, cls_index: np.ndarray, \n",
    "                   i: int, metric: str = \"euclidean\", n_neighbors=1) :\n",
    "    \" This function computes the distance from a point x_i to their nearest enemy\"\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1)).fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    \n",
    "    X_ = X[np.logical_not(cls_index[y[i]])]\n",
    "    y_ = y[np.logical_not(cls_index[y[i]])]\n",
    "    \n",
    "    neigh = KNeighborsClassifier(n_neighbors=n_neighbors, metric=metric)\n",
    "    neigh.fit(X_, y_) \n",
    "    dist_enemy, pos_enemy = neigh.kneighbors([X[i, :]])\n",
    "    dist_enemy = np.reshape(dist_enemy, (n_neighbors,))\n",
    "    pos_enemy = np.reshape(pos_enemy, (n_neighbors,))\n",
    "    return dist_enemy, pos_enemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighboor_same_class (X: np.ndarray, y: np.ndarray, cls_index: np.ndarray,\n",
    "                                  i: int, metric: str = \"euclidean\", n_neighbors=1) :\n",
    "    \" This function computes the distance from a point x_i to their nearest neighboor from its own class\"\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1)).fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    \n",
    "    query = X[i, :]\n",
    "    label_query = y[i]\n",
    "    X_ = X[cls_index[label_query]]\n",
    "    y_ = y[cls_index[label_query]]\n",
    "    \n",
    "    pos_query = np.where(np.all(X_==query,axis=1))\n",
    "    X_ = np.delete(X_, pos_query, axis = 0)\n",
    "    y_ = np.delete(y_, pos_query, axis = 0) \n",
    "    \n",
    "    neigh = KNeighborsClassifier(n_neighbors=n_neighbors, metric=metric)\n",
    "    neigh.fit(X_, y_) \n",
    "    dist_neigh, pos_neigh = neigh.kneighbors([X[i, :]])\n",
    "    dist_neigh = np.reshape(dist_neigh, (n_neighbors,))\n",
    "    pos_neigh = np.reshape(pos_neigh, (n_neighbors,))\n",
    "    return dist_neigh, pos_neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intra_extra(X: np.ndarray, y: np.ndarray, cls_index: np.ndarray):\n",
    "    intra = np.sum([nearest_neighboor_same_class (X, y, cls_index, i)[0] for i in range(np.shape(X)[0])])\n",
    "    extra = np.sum([nearest_enemy (X, y, cls_index, i)[0] for i in range(np.shape(X)[0])])\n",
    "    return intra/extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_N2 (X: np.ndarray, y: np.ndarray, cls_index: np.ndarray):\n",
    "    intra_extra_ = intra_extra(X, y, cls_index)\n",
    "    return intra_extra_/(1+intra_extra_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1782317865334682"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_N2(X, y, cls_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error Rate of the Nearest Neighbor Classifier (N3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_N3 (X: np.ndarray, y: np.ndarray, metric: str = \"euclidean\") -> float:\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1)).fit(X)\n",
    "    X_ = scaler.transform(X)\n",
    "    loo = LeaveOneOut()\n",
    "    loo.get_n_splits(X_, y)\n",
    "    \n",
    "    y_test_ = []\n",
    "    pred_y_ = []\n",
    "    for train_index, test_index in loo.split(X_):\n",
    "        X_train, X_test = X_[train_index], X_[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model = KNeighborsClassifier(n_neighbors=1, metric=metric)\n",
    "        model.fit(X_train, y_train)\n",
    "        pred_y = model.predict(X_test)\n",
    "        y_test_.append(y_test)\n",
    "        pred_y_.append(pred_y)\n",
    "    \n",
    "    error = 1 - accuracy_score(y_test_, pred_y_)\n",
    "    return error\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.046666666666666634"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_N3(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local Set Average Cardinality (LSC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LS_i (X: np.ndarray, y: np.ndarray, i: int, metric: str = \"euclidean\"):\n",
    "    dist_enemy, pos_enemy = nearest_enemy(X, y, cls_index, i)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1)).fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    dist_ = distance.cdist(X, [X[i, :]], metric=metric)\n",
    "    X_j = dist_[np.logical_and(dist_ < dist_enemy, dist_ != 0)]\n",
    "    return X_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSC (X, y):\n",
    "    n = np.shape(X)[0]\n",
    "    x = [np.shape(LS_i(X, y, i)) for i in range(n)]\n",
    "    return 1 - np.sum(x)/n**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8243555555555555"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSC(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-Linearity of the Nearest Neighbor Classifier (N4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_N4(X: np.ndarray, y: np.ndarray, cls_index: np.ndarray, \n",
    "          metric: str = \"euclidean\", p=2, n_neighbors=1) -> np.ndarray:\n",
    "    interp_X = []\n",
    "    interp_y = []\n",
    "\n",
    "    # 0-1 scaler\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1)).fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    \n",
    "    for idx in cls_index:\n",
    "        #creates a new dataset by interpolating pairs of training examples of the same class.\n",
    "        X_ = X[idx]\n",
    "\n",
    "        #two examples from the same class are chosen randomly and\n",
    "        #they are linearly interpolated (with random coefficients), producing a new example.\n",
    "        A = np.random.choice(X_.shape[0], X_.shape[0])\n",
    "        A = X_[A]\n",
    "        B = np.random.choice(X_.shape[0], X_.shape[0])\n",
    "        B = X_[B]\n",
    "        delta = np.random.ranf(X_.shape)\n",
    "\n",
    "        interp_X_ = A + ((B - A) * delta)\n",
    "        interp_y_ = y[idx]\n",
    "\n",
    "        interp_X.append(interp_X_)\n",
    "        interp_y.append(interp_y_)\n",
    "    \n",
    "    # join the datasets\n",
    "    X_test = np.concatenate(interp_X)\n",
    "    y_test = np.concatenate(interp_y)\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors, p=p, metric=metric).fit(X, y)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    error = 1 - accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return error\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_N4(X, y, cls_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Measures\n",
    "- Average number of features per dimension (T2)\n",
    "- Average number of PCA dimensions per points (T3)\n",
    "- Ratio of the PCA Dimension to the Original Dimension (T4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_pca_tx(X: np.ndarray) -> t.Dict[str, t.Any]:\n",
    "    \"\"\"Precompute PCA to Tx complexity measures.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : :obj:`np.ndarray`, optional\n",
    "            Attributes from fitted data.\n",
    "    Returns\n",
    "    -------\n",
    "    :obj:`dict`\n",
    "        With following precomputed items:\n",
    "        - ``m`` (:obj:`int`): Number of features.\n",
    "        - ``m_`` (:obj:`int`):  Number of features after PCA with 0.95.\n",
    "        - ``n`` (:obj:`int`): Number of examples.\n",
    "    \"\"\"\n",
    "    prepcomp_vals = {}\n",
    "\n",
    "    scaler = StandardScaler().fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    pca = PCA(n_components=0.95)\n",
    "    pca.fit(X)\n",
    "\n",
    "    m_ = pca.explained_variance_ratio_.shape[0]\n",
    "    m = X.shape[1]\n",
    "    n = X.shape[0]\n",
    "\n",
    "    prepcomp_vals[\"m_\"] = m_\n",
    "    prepcomp_vals[\"m\"] = m\n",
    "    prepcomp_vals[\"n\"] = n\n",
    "\n",
    "    return prepcomp_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average number of features per dimension (T2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_T2(m: int, n: int) -> float:\n",
    "    return m/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ratio of the PCA Dimension to the Original Dimension (T4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_T3(m_: int, n: int) -> float:\n",
    "    return m_/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ratio of the PCA Dimension to the Original Dimension (T4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_T4(m: int, m_: int) -> float:\n",
    "    return m_/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "precomp_pca = precompute_pca_tx(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = precomp_pca['m']\n",
    "n = precomp_pca['n']\n",
    "m_ = precomp_pca['m_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02666666666666667"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_T2(m, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013333333333333334"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_T3(m_, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_T4(m, m_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
