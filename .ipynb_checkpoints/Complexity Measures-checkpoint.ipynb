{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as t\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from scipy.sparse.csgraph import minimum_spanning_tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data = load_iris()\n",
    "#data = load_breast_cancer()\n",
    "y = data.target\n",
    "X = data.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Some useful things to support complexity measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_fx(X: np.ndarray, y: np.ndarray) -> t.Dict[str, t.Any]:\n",
    "    \"\"\"Precompute some useful things to support complexity measures.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : :obj:`np.ndarray`, optional\n",
    "            Attributes from fitted data.\n",
    "    y : :obj:`np.ndarray`, optional\n",
    "            Target attribute from fitted data.\n",
    "    Returns\n",
    "    -------\n",
    "    :obj:`dict`\n",
    "        With following precomputed items:\n",
    "        - ``ovo_comb`` (:obj:`list`): List of all class OVO combination, \n",
    "            i.e., [(0,1), (0,2) ...].\n",
    "        - ``cls_index`` (:obj:`list`):  The list of boolean vectors\n",
    "            indicating the example of each class. \n",
    "        - ``cls_n_ex`` (:obj:`np.ndarray`): The number of examples in\n",
    "            each class. The array indexes represent the classes.\n",
    "    \"\"\"\n",
    "\n",
    "    prepcomp_vals = {}\n",
    "    \n",
    "    classes, class_freqs = np.unique(y, return_counts=True)\n",
    "    cls_index = [np.equal(y, i) for i in range(classes.shape[0])]\n",
    "\n",
    "    #cls_n_ex = np.array([np.sum(aux) for aux in cls_index])\n",
    "    cls_n_ex = list(class_freqs)\n",
    "    ovo_comb = list(itertools.combinations(range(classes.shape[0]), 2))\n",
    "    prepcomp_vals[\"ovo_comb\"] = ovo_comb\n",
    "    prepcomp_vals[\"cls_index\"] = cls_index\n",
    "    prepcomp_vals[\"cls_n_ex\"] = cls_n_ex\n",
    "    return prepcomp_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "precomp_fx = precompute_fx(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_index = precomp_fx['cls_index']\n",
    "cls_n_ex = precomp_fx['cls_n_ex']\n",
    "ovo_comb = precomp_fx['ovo_comb']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature-based Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum Fisher’s Discriminant Ratio (F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerator (X: np.ndarray, cls_index, cls_n_ex, i) -> float:\n",
    "    return np.sum([cls_n_ex[j]*np.power((np.mean(X[cls_index[j], i])-\n",
    "                                         np.mean(X[:, i], axis=0)),2) for j in range (len(cls_index))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denominator (X: np.ndarray, cls_index, cls_n_ex, i) -> float:\n",
    "    return np.sum([np.sum(np.power(X[cls_index[j], i]-np.mean(X[cls_index[j], i], axis=0), 2)) \n",
    "                   for j in range(0, len(cls_n_ex))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rfi (X: np.ndarray, cls_index, cls_n_ex) -> float:\n",
    "    return [numerator (X, cls_index, cls_n_ex, i)/denominator(X, cls_index, cls_n_ex, i)\n",
    "            for i in range(np.shape(X)[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_F1(X: np.ndarray, cls_index: np.ndarray, cls_n_ex: np.ndarray) -> float:\n",
    "    return 1/(1 + np.max(compute_rfi (X, cls_index, cls_n_ex)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05862828094263205"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_F1(X, cls_index, cls_n_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Directional-vector Maximum Fisher’s Discriminant Ratio (F1v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_F1v(X: np.ndarray, ovo_comb: np.ndarray, cls_index: np.ndarray) ->float:\n",
    "    df_list = []\n",
    "    \n",
    "    for idx1, idx2 in ovo_comb:\n",
    "        y_class1 = cls_index[idx1]\n",
    "        y_class2 = cls_index[idx2]\n",
    "        dF = dVector(X, y_class1, y_class2)\n",
    "        df_list.append(1/(1+dF))\n",
    "        \n",
    "    return np.mean(df_list)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dVector(X: np.ndarray, y_class1: np.ndarray, y_class2: np.ndarray) -> float:\n",
    "    X_class1 = X[y_class1]; u_class1 = np.mean(X_class1, axis= 0)\n",
    "    X_class2 = X[y_class2]; u_class2 = np.mean(X_class2, axis= 0)\n",
    "    \n",
    "    W = ((np.shape(X_class1)[0]/ (np.shape(X_class1)[0] + np.shape(X_class2)[0]))* np.cov(X_class1.T)) \\\n",
    "     + (np.shape(X_class2)[0]/(np.shape(X_class1)[0] + (np.shape(X_class2)[0])) * np.cov(X_class2.T))\n",
    "    \n",
    "    d = np.dot(np.linalg.inv(W), (u_class1 - u_class2))\n",
    "    \n",
    "    B = np.dot((u_class1 - u_class2),((u_class1 - u_class2).T))\n",
    "    \n",
    "    return np.dot(np.dot(d.T, B), d)/ np.dot(np.dot(d.T, W), d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010007003139831777"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_F1v(X, ovo_comb, cls_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Volume of Overlapping Region (F2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _minmax(X: np.ndarray, class1: np.ndarray, class2: np.ndarray) -> np.ndarray:\n",
    "    \"\"\" This function computes the minimum of the maximum values per class\n",
    "    for all features.\n",
    "    \"\"\"\n",
    "    max_cls = np.zeros((2, X.shape[1]))\n",
    "    max_cls[0, :] = np.max(X[class1], axis=0)\n",
    "    max_cls[1, :] = np.max(X[class2], axis=0)\n",
    "    aux = np.min(max_cls, axis=0)\n",
    "    \n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _minmin(X: np.ndarray, class1: np.ndarray, class2: np.ndarray) -> np.ndarray:\n",
    "    \"\"\" This function computes the minimum of the minimum values per class\n",
    "    for all features.\n",
    "    \"\"\"\n",
    "    min_cls = np.zeros((2, X.shape[1]))\n",
    "    min_cls[0, :] = np.min(X[class1], axis=0)\n",
    "    min_cls[1, :] = np.min(X[class2], axis=0)\n",
    "    aux = np.min(min_cls, axis=0)\n",
    "    \n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _maxmin(X: np.ndarray, class1: np.ndarray, class2: np.ndarray) -> np.ndarray:\n",
    "    \"\"\" This function computes the maximum of the minimum values per class\n",
    "    for all features.\n",
    "    \"\"\"\n",
    "    min_cls = np.zeros((2, X.shape[1]))\n",
    "    min_cls[0, :] = np.min(X[class1], axis=0)\n",
    "    min_cls[1, :] = np.min(X[class2], axis=0)\n",
    "    aux = np.max(min_cls, axis=0)\n",
    "    \n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _maxmax(X: np.ndarray, class1: np.ndarray, class2: np.ndarray) -> np.ndarray:\n",
    "    \"\"\" This function computes the maximum of the maximum values per class\n",
    "    for all features. \n",
    "    \"\"\"\n",
    "    max_cls = np.zeros((2, X.shape[1]))\n",
    "    max_cls[0, :] = np.max(X[class1], axis=0)\n",
    "    max_cls[1, :] = np.max(X[class2], axis=0)\n",
    "    aux = np.max(max_cls, axis=0)\n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_F2(X: np.ndarray, ovo_comb: np.ndarray, cls_index: np.ndarray) -> float:\n",
    "    f2_list = []\n",
    "    \n",
    "    for idx1, idx2 in ovo_comb:\n",
    "        y_class1 = cls_index[idx1]\n",
    "        y_class2 = cls_index[idx2]\n",
    "        zero_ = np.zeros(np.shape(X)[1])\n",
    "        overlap_ = np.maximum(zero_, _minmax(X, y_class1, y_class2)-_maxmin(X, y_class1, y_class2))\n",
    "        range_ = _maxmax(X, y_class1, y_class2)-_minmin(X, y_class1, y_class2)\n",
    "        ratio = overlap_/range_\n",
    "        f2_list.append(np.prod(ratio))\n",
    "        \n",
    "    return np.mean(f2_list)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0063817663817663794"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_F2(X, ovo_comb, cls_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum Individual Feature Efficiency (F3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_f3(X_: np.ndarray, minmax_: np.ndarray, maxmin_: np.ndarray) -> np.ndarray:\n",
    "    \"\"\" This function computes the F3 complexity measure given minmax and maxmin.\"\"\"\n",
    "\n",
    "    overlapped_region_by_feature = np.logical_and(X_ >= maxmin_, X_ <= minmax_)\n",
    "\n",
    "    n_fi = np.sum(overlapped_region_by_feature, axis=0)\n",
    "    idx_min = np.argmin(n_fi)\n",
    "\n",
    "    return idx_min, n_fi, overlapped_region_by_feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_F3(X: np.ndarray, ovo_comb: np.ndarray, cls_index: np.ndarray, cls_n_ex: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"TODO\n",
    "    \"\"\"\n",
    "    f3 = []\n",
    "    for idx1, idx2 in ovo_comb:\n",
    "        idx_min, n_fi, _ = _compute_f3(X, _minmax(X, cls_index[idx1], cls_index[idx2]),\n",
    "        _maxmin(X, cls_index[idx1], cls_index[idx2]))\n",
    "    f3.append(n_fi[idx_min] / (cls_n_ex[idx1] + cls_n_ex[idx2]))\n",
    "\n",
    "    return np.mean(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_F3(X, ovo_comb, cls_index, cls_n_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collective Feature Efficiency (F4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_F4(X: np.ndarray, ovo_comb, cls_index, cls_n_ex) -> np.ndarray:\n",
    "    \"\"\"TODO\n",
    "    \"\"\"\n",
    "\n",
    "    f4 = []\n",
    "    for idx1, idx2 in ovo_comb:\n",
    "        aux = 0\n",
    "\n",
    "        y_class1 = cls_index[idx1]\n",
    "        y_class2 = cls_index[idx2]\n",
    "        sub_set = np.logical_or(y_class1, y_class2)\n",
    "        y_class1 = y_class1[sub_set]\n",
    "        y_class2 = y_class2[sub_set]\n",
    "        X_ = X[sub_set, :]\n",
    "        # X_ = X[np.logical_or(y_class1, y_class2),:]\n",
    "    \n",
    "        while X_.shape[1] > 0 and X_.shape[0] > 0:\n",
    "            # True if the example is in the overlapping region\n",
    "            idx_min, _, overlapped_region_by_feature = _compute_f3(X_,_minmax(X_, y_class1, y_class2),_maxmin(X_, y_class1, y_class2))\n",
    "\n",
    "            # boolean that if True, this example is in the overlapping region\n",
    "            overlapped_region = overlapped_region_by_feature[:, idx_min]\n",
    "\n",
    "            # removing the non overlapped features\n",
    "            X_ = X_[overlapped_region, :]\n",
    "            y_class1 = y_class1[overlapped_region]\n",
    "            y_class2 = y_class2[overlapped_region]\n",
    "\n",
    "            if X_.shape[0] > 0:\n",
    "                aux = X_.shape[0]\n",
    "            else:\n",
    "                aux = 0\n",
    "            \n",
    "            # removing the most efficient feature\n",
    "            X_ = np.delete(X_, idx_min, axis=1)\n",
    "\n",
    "        f4.append(aux/(cls_n_ex[idx1] + cls_n_ex[idx2]))\n",
    "    return np.mean(f4)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.043333333333333335"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_F4(X, ovo_comb, cls_index, cls_n_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neighborhood Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ratio of Intra/Extra Class Nearest Neighbor Distance (N2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_enemy (X: np.ndarray, y: np.ndarray, cls_index: np.ndarray, \n",
    "                   i: int, metric: str = \"euclidean\", n_neighbors=1) :\n",
    "    \" This function computes the distance from a point x_i to their nearest enemy\"\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1)).fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    \n",
    "    X_ = X[np.logical_not(cls_index[y[i]])]\n",
    "    y_ = y[np.logical_not(cls_index[y[i]])]\n",
    "    \n",
    "    neigh = KNeighborsClassifier(n_neighbors=n_neighbors, metric=metric)\n",
    "    neigh.fit(X_, y_) \n",
    "    dist_enemy, pos_enemy = neigh.kneighbors([X[i, :]])\n",
    "    dist_enemy = np.reshape(dist_enemy, (n_neighbors,))\n",
    "    pos_enemy_ = np.reshape(pos_enemy, (n_neighbors,))\n",
    "    query = X_[pos_enemy_, :]\n",
    "    pos_enemy = np.where(np.all(X==query,axis=1))\n",
    "    pos_enemy = np.reshape(pos_enemy, (n_neighbors,))\n",
    "    return dist_enemy, pos_enemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighboor_same_class (X: np.ndarray, y: np.ndarray, cls_index: np.ndarray,\n",
    "                                  i: int, metric: str = \"euclidean\", n_neighbors=1) :\n",
    "    \" This function computes the distance from a point x_i to their nearest neighboor from its own class\"\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1)).fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    \n",
    "    query = X[i, :]\n",
    "    label_query = y[i]\n",
    "    X_ = X[cls_index[label_query]]\n",
    "    y_ = y[cls_index[label_query]]\n",
    "    \n",
    "    pos_query = np.where(np.all(X_==query,axis=1))\n",
    "    X_ = np.delete(X_, pos_query, axis = 0)\n",
    "    y_ = np.delete(y_, pos_query, axis = 0) \n",
    "    \n",
    "    neigh = KNeighborsClassifier(n_neighbors=n_neighbors, metric=metric)\n",
    "    neigh.fit(X_, y_) \n",
    "    dist_neigh, pos_neigh = neigh.kneighbors([X[i, :]])\n",
    "    dist_neigh = np.reshape(dist_neigh, (n_neighbors,))\n",
    "    pos_neigh = np.reshape(pos_neigh, (n_neighbors,))\n",
    "    return dist_neigh, pos_neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intra_extra(X: np.ndarray, y: np.ndarray, cls_index: np.ndarray):\n",
    "    intra = np.sum([nearest_neighboor_same_class (X, y, cls_index, i)[0] for i in range(np.shape(X)[0])])\n",
    "    extra = np.sum([nearest_enemy (X, y, cls_index, i)[0] for i in range(np.shape(X)[0])])\n",
    "    return intra/extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_N2 (X: np.ndarray, y: np.ndarray, cls_index: np.ndarray):\n",
    "    intra_extra_ = intra_extra(X, y, cls_index)\n",
    "    return intra_extra_/(1+intra_extra_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1782317865334682"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_N2(X, y, cls_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error Rate of the Nearest Neighbor Classifier (N3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_N3 (X: np.ndarray, y: np.ndarray, metric: str = \"euclidean\") -> float:\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1)).fit(X)\n",
    "    X_ = scaler.transform(X)\n",
    "    loo = LeaveOneOut()\n",
    "    loo.get_n_splits(X_, y)\n",
    "    \n",
    "    y_test_ = []\n",
    "    pred_y_ = []\n",
    "    for train_index, test_index in loo.split(X_):\n",
    "        X_train, X_test = X_[train_index], X_[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model = KNeighborsClassifier(n_neighbors=1, metric=metric)\n",
    "        model.fit(X_train, y_train)\n",
    "        pred_y = model.predict(X_test)\n",
    "        y_test_.append(y_test)\n",
    "        pred_y_.append(pred_y)\n",
    "    \n",
    "    error = 1 - accuracy_score(y_test_, pred_y_)\n",
    "    return error\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.046666666666666634"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_N3(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_matrix (X: np.ndarray):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1)).fit(X)\n",
    "    X = scaler.transform(X)\n",
    "\n",
    "    dist = distance.cdist(X, X, 'euclidean')\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "D = distance_matrix(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radios (D: np.ndarray, y: np.ndarray, X: np.ndarray, \n",
    "                        cls_index:np.ndarray, i: int) -> float:\n",
    "    d_i, x_j = nearest_enemy(X, y, cls_index, i)\n",
    "    d_j, x_k = nearest_enemy(X, y, cls_index, x_j[0])\n",
    "    if (i == x_k[0]):\n",
    "        return d_i/2\n",
    "    else :\n",
    "        d_t = radios (D, y, X, cls_index, x_j[0]) \n",
    "        var = d_i - d_t\n",
    "        return d_i - d_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "spheres = [radios(D, y, X, cls_index, i) for i in range(X.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperspher (D: np.ndarray, y: np.ndarray, X: np.ndarray, cls_index:np.ndarray) :\n",
    "\n",
    "  aux = [radios(D, y, X, cls_index, i) for i in range(X.shape[0])]\n",
    "  return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.36167364]),\n",
       " array([0.24950034]),\n",
       " array([0.3055788]),\n",
       " array([0.27472733]),\n",
       " array([0.39088173]),\n",
       " array([0.37838014]),\n",
       " array([0.32595467]),\n",
       " array([0.32773212]),\n",
       " array([0.26859901]),\n",
       " array([0.29016676]),\n",
       " array([0.33843654]),\n",
       " array([0.32589656]),\n",
       " array([0.28439124]),\n",
       " array([0.35003661]),\n",
       " array([0.49677778]),\n",
       " array([0.54112226]),\n",
       " array([0.41456086]),\n",
       " array([0.33750709]),\n",
       " array([0.37659395]),\n",
       " array([0.40790388]),\n",
       " array([0.240493]),\n",
       " array([0.36015883]),\n",
       " array([0.43529861]),\n",
       " array([0.21029417]),\n",
       " array([0.30724617]),\n",
       " array([0.22997973]),\n",
       " array([0.27071808]),\n",
       " array([0.35510809]),\n",
       " array([0.33524687]),\n",
       " array([0.28149169]),\n",
       " array([0.25507065]),\n",
       " array([0.21639515]),\n",
       " array([0.52890881]),\n",
       " array([0.53156324]),\n",
       " array([0.25938586]),\n",
       " array([0.30423638]),\n",
       " array([0.30041325]),\n",
       " array([0.41741605]),\n",
       " array([0.29109522]),\n",
       " array([0.3270765]),\n",
       " array([0.3460104]),\n",
       " array([0.20447397]),\n",
       " array([0.32761917]),\n",
       " array([0.26249241]),\n",
       " array([0.34883718]),\n",
       " array([0.22372367]),\n",
       " array([0.42585652]),\n",
       " array([0.30333691]),\n",
       " array([0.34248161]),\n",
       " array([0.30996296]),\n",
       " array([0.13568573]),\n",
       " array([0.12703194]),\n",
       " array([0.09176852]),\n",
       " array([0.18744731]),\n",
       " array([0.05066622]),\n",
       " array([0.16161679]),\n",
       " array([0.10606449]),\n",
       " array([0.25819302]),\n",
       " array([0.10035313]),\n",
       " array([0.09981952]),\n",
       " array([0.2976364]),\n",
       " array([0.11959847]),\n",
       " array([0.21790436]),\n",
       " array([0.05495112]),\n",
       " array([0.27048684]),\n",
       " array([0.15857814]),\n",
       " array([0.13088263]),\n",
       " array([0.2545491]),\n",
       " array([0.05066622]),\n",
       " array([0.25018022]),\n",
       " array([0.04392052]),\n",
       " array([0.1609726]),\n",
       " array([0.07884862]),\n",
       " array([0.1020027]),\n",
       " array([0.11618006]),\n",
       " array([0.12167476]),\n",
       " array([0.10299476]),\n",
       " array([0.05478224]),\n",
       " array([0.08725554]),\n",
       " array([0.32717184]),\n",
       " array([0.25816993]),\n",
       " array([0.29311658]),\n",
       " array([0.22865198]),\n",
       " array([0.05139585]),\n",
       " array([0.15903615]),\n",
       " array([0.14923145]),\n",
       " array([0.12979724]),\n",
       " array([0.11047612]),\n",
       " array([0.22032344]),\n",
       " array([0.15065483]),\n",
       " array([0.21958321]),\n",
       " array([0.08698849]),\n",
       " array([0.22359018]),\n",
       " array([0.2664494]),\n",
       " array([0.21345188]),\n",
       " array([0.2206572]),\n",
       " array([0.1937259]),\n",
       " array([0.11618006]),\n",
       " array([0.26104475]),\n",
       " array([0.20122582]),\n",
       " array([0.33093766]),\n",
       " array([0.08539384]),\n",
       " array([0.1969967]),\n",
       " array([0.10695754]),\n",
       " array([0.19992292]),\n",
       " array([0.34996443]),\n",
       " array([0.09981952]),\n",
       " array([0.2277054]),\n",
       " array([0.1475136]),\n",
       " array([0.42235648]),\n",
       " array([0.1062865]),\n",
       " array([0.11924932]),\n",
       " array([0.13424481]),\n",
       " array([0.15343076]),\n",
       " array([0.26207759]),\n",
       " array([0.22041779]),\n",
       " array([0.05478224]),\n",
       " array([0.4673364]),\n",
       " array([0.46593275]),\n",
       " array([0.05066622]),\n",
       " array([0.23950891]),\n",
       " array([0.16090609]),\n",
       " array([0.37271286]),\n",
       " array([0.07123361]),\n",
       " array([0.18496595]),\n",
       " array([0.1833313]),\n",
       " array([0.06840582]),\n",
       " array([0.05765771]),\n",
       " array([0.17327153]),\n",
       " array([0.09176852]),\n",
       " array([0.23925459]),\n",
       " array([0.42810581]),\n",
       " array([0.20528222]),\n",
       " array([0.05066622]),\n",
       " array([0.07757703]),\n",
       " array([0.36285471]),\n",
       " array([0.27258484]),\n",
       " array([0.07787714]),\n",
       " array([0.04392052]),\n",
       " array([0.13808219]),\n",
       " array([0.25690256]),\n",
       " array([0.20523661]),\n",
       " array([0.08539384]),\n",
       " array([0.2509713]),\n",
       " array([0.32046771]),\n",
       " array([0.19750548]),\n",
       " array([0.08867765]),\n",
       " array([0.0861451]),\n",
       " array([0.21614394]),\n",
       " array([0.05370073])]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperspher(D, y, X, cls_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local Set Average Cardinality (LSC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LS_i (X: np.ndarray, y: np.ndarray, i: int, metric: str = \"euclidean\"):\n",
    "    dist_enemy, pos_enemy = nearest_enemy(X, y, cls_index, i)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1)).fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    dist_ = distance.cdist(X, [X[i, :]], metric=metric)\n",
    "    X_j = dist_[np.logical_and(dist_ < dist_enemy, dist_ != 0)]\n",
    "    return X_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSC (X, y):\n",
    "    n = np.shape(X)[0]\n",
    "    x = [np.shape(LS_i(X, y, i)) for i in range(n)]\n",
    "    return 1 - np.sum(x)/n**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8243555555555555"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSC(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-Linearity of the Nearest Neighbor Classifier (N4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_N4(X: np.ndarray, y: np.ndarray, cls_index: np.ndarray, \n",
    "          metric: str = \"euclidean\", p=2, n_neighbors=1) -> np.ndarray:\n",
    "    interp_X = []\n",
    "    interp_y = []\n",
    "\n",
    "    # 0-1 scaler\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1)).fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    \n",
    "    for idx in cls_index:\n",
    "        #creates a new dataset by interpolating pairs of training examples of the same class.\n",
    "        X_ = X[idx]\n",
    "\n",
    "        #two examples from the same class are chosen randomly and\n",
    "        #they are linearly interpolated (with random coefficients), producing a new example.\n",
    "        A = np.random.choice(X_.shape[0], X_.shape[0])\n",
    "        A = X_[A]\n",
    "        B = np.random.choice(X_.shape[0], X_.shape[0])\n",
    "        B = X_[B]\n",
    "        delta = np.random.ranf(X_.shape)\n",
    "\n",
    "        interp_X_ = A + ((B - A) * delta)\n",
    "        interp_y_ = y[idx]\n",
    "\n",
    "        interp_X.append(interp_X_)\n",
    "        interp_y.append(interp_y_)\n",
    "    \n",
    "    # join the datasets\n",
    "    X_test = np.concatenate(interp_X)\n",
    "    y_test = np.concatenate(interp_y)\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors, p=p, metric=metric).fit(X, y)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    error = 1 - accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return error\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.033333333333333326"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_N4(X, y, cls_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Measures\n",
    "- Average number of features per dimension (T2)\n",
    "- Average number of PCA dimensions per points (T3)\n",
    "- Ratio of the PCA Dimension to the Original Dimension (T4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_pca_tx(X: np.ndarray) -> t.Dict[str, t.Any]:\n",
    "    \"\"\"Precompute PCA to Tx complexity measures.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : :obj:`np.ndarray`, optional\n",
    "            Attributes from fitted data.\n",
    "    Returns\n",
    "    -------\n",
    "    :obj:`dict`\n",
    "        With following precomputed items:\n",
    "        - ``m`` (:obj:`int`): Number of features.\n",
    "        - ``m_`` (:obj:`int`):  Number of features after PCA with 0.95.\n",
    "        - ``n`` (:obj:`int`): Number of examples.\n",
    "    \"\"\"\n",
    "    prepcomp_vals = {}\n",
    "\n",
    "    scaler = StandardScaler().fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    pca = PCA(n_components=0.95)\n",
    "    pca.fit(X)\n",
    "\n",
    "    m_ = pca.explained_variance_ratio_.shape[0]\n",
    "    m = X.shape[1]\n",
    "    n = X.shape[0]\n",
    "\n",
    "    prepcomp_vals[\"m_\"] = m_\n",
    "    prepcomp_vals[\"m\"] = m\n",
    "    prepcomp_vals[\"n\"] = n\n",
    "\n",
    "    return prepcomp_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average number of features per dimension (T2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_T2(m: int, n: int) -> float:\n",
    "    return m/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average number of PCA dimensions per points (T3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_T3(m_: int, n: int) -> float:\n",
    "    return m_/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ratio of the PCA Dimension to the Original Dimension (T4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_T4(m: int, m_: int) -> float:\n",
    "    return m_/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "precomp_pca = precompute_pca_tx(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = precomp_pca['m']\n",
    "n = precomp_pca['n']\n",
    "m_ = precomp_pca['m_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02666666666666667"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_T2(m, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013333333333333334"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_T3(m_, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_T4(m, m_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
